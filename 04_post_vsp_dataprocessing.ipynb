{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b55bf9-8fbc-4133-9921-db4d8cc8c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy import sparse, io\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "RAW_TWEETS_PATH = \"/data/dnc2020/raw_tweets/\"\n",
    "PARQUET_TWEET_PATH = '/data/navid/processed_tweets'\n",
    "PARQUET_USER_PATH = \"/data/navid/processed_users\"\n",
    "PARQUET_RTNET_PATH = \"/data/kenny/processed_rt_network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "429583ec-696d-40f3-ac0a-3e882aa0e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/kjoseph/miniconda3/envs/kenny_gen/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/07/25 11:05:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/25 11:05:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "## We use spark to analyze the data efficiently. You may opt for a different format\n",
    "## Also note we here assume a machine with a reasonably large number of cores (16) \n",
    "## and RAM (at least 32 GB). Adjust below accordingly\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[{}]\".format(16))\n",
    "    .config(\"spark.driver.memory\", \"{}g\".format(50))\n",
    "    .config(\"spark.driver.maxResultSize\", f\"{10}g\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c067b39-7de9-4d57-9685-d276eca8a593",
   "metadata": {},
   "source": [
    "# Write out subset of tweets from Bernie Users\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb3847a-001e-486c-8173-3cddd2c88f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_tweets_df = spark.read.parquet(os.path.join(PARQUET_TWEET_PATH, '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f54fc89a-fab8-4d30-a3fd-eb12385e5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_res = spark.read.csv(\"/data/dnc2020/bernie_vsp.csv\",sep=\" \", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb90dcb-d984-4e7e-9223-5659d5d4cda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|uid |\n",
      "+----+\n",
      "|765 |\n",
      "|1033|\n",
      "|1084|\n",
      "|1265|\n",
      "|1999|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_res.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a113acf2-ce2a-4f0d-ac56-0b146d009b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tweets = clustering_res.join(all_tweets_df, ['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94994ec0-8e1f-491c-bf4c-47876bb5ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cluster_tweets.write.parquet(\"/data/dnc2020/tweets_clustering\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02646d-373a-45ae-ba19-8e43edea0e7c",
   "metadata": {},
   "source": [
    "# Evaluation: RTs of Candidates (generate data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f3e013-760b-4094-a571-68b46dad944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accts = [(\"939091\", \"JoeBiden\"),\n",
    "(\"1193981789787824129\", \"Mike2020\"),\n",
    "(\"226222147\", \"PeteButtigieg\"),\n",
    "(\"426028646\", \"JohnDelaney\"),\n",
    "(\"26637348\", \"TulsiGabbard\"),\n",
    "(\"33537967\", \"amyklobuchar\"),\n",
    "(\"61636488\", \"DevalPatrick\"),\n",
    "(\"216776631\", \"BernieSanders\"),\n",
    "(\"949934436\", \"TomSteyer\"),\n",
    "(\"357606935\", \"ewarren\"),\n",
    "(\"2228878592\", \"AndrewYang\"),\n",
    "(\"4797361833\", \"TomPerez\"),\n",
    "(\"1108472017144201216\", \"TrumpWarRoom\"),\n",
    "(\"818910970567344128\", \"VP45\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "488092fa-c772-4bd4-8238-200162f47fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[{}]\".format(16))\n",
    "    .config(\"spark.driver.memory\", \"{}g\".format(50))\n",
    "    .config(\"spark.driver.maxResultSize\", f\"{20}g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eab84f37-240c-4600-a536-32aaa232fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rt_net = spark.read.parquet(\"data/trimmed_rtnet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24db8a06-07e5-4bad-a97c-18f5de76a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_df = spark.createDataFrame(accts, schema=T.StructType([\n",
    "                    T.StructField('rt_uid', T.StringType(), True), \n",
    "                   T.StructField('sn', T.StringType(), True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e24d2bf-6260-400b-9ad9-43696b9addb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rt_net = trimmed_rt_net.join(acct_df, \"rt_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "863914d7-8d88-4950-852a-6ea5676863ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trimmed_rt_net.write.parquet(\"rtnet_eval\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1d044-c1b5-4f41-98a3-4a030851927a",
   "metadata": {},
   "source": [
    "# Evaluation: Most Common Identities Per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db9d78c-997f-4453-b598-877de5ffc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_desc_df = spark.read.parquet(\"/data/dnc2020/user_descript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325ea69-2aef-46b1-9b2e-7aacf718f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from personal_identifiers import *\n",
    "\n",
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def extract_pid(bio):\n",
    "    if bio is None:\n",
    "        return \"\"\n",
    "    return find_identifiers_simple(bio)[0]\n",
    "\n",
    "user_to_pi = (user_desc_df\n",
    " .withColumn('pi', extract_pid('description'))\n",
    " .select(F.col(\"id\"),F.explode(F.col(\"pi\")))\n",
    " .dropDuplicates(subset=['id','col'])\n",
    ")\n",
    "\n",
    "user_to_pi.write.parquet(\"/data/dnc2020/user_pi_net\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a053946-242d-4133-a9de-c0cf4e3ab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_pi = spark.read.parquet(\"/data/dnc2020/user_pi_net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d836d0-de85-4f06-8120-e5e3368de084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------+\n",
      "|uid |grp|utype   |\n",
      "+----+---+--------+\n",
      "|765 |27 |ordinary|\n",
      "|1033|11 |ordinary|\n",
      "|1084|11 |ordinary|\n",
      "|1265|11 |ordinary|\n",
      "|1999|3  |ordinary|\n",
      "+----+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_res = spark.read.csv(\"bernie_vsp_yz.csv\",sep=\" \",\n",
    "                                header=True)\n",
    "clustering_res.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89ffca1-3d5a-4848-a623-e076358d6ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|id      |col                    |\n",
      "+--------+-----------------------+\n",
      "|591     |build your brand online|\n",
      "|1904551 |mama                   |\n",
      "|9507972 |espace2                |\n",
      "|12517802|action                 |\n",
      "|14121921|commercial voice talent|\n",
      "+--------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_to_pi.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881f3f6a-48f7-43b6-9cfe-5e8f815cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = user_to_pi.join(clustering_res,\n",
    "                     user_to_pi.id == clustering_res.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7d23a9-c449-40ea-9f1e-45e873a8e87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mg.groupby([\"col\",\"grp\",\"utype\"]).count().write.parquet(\"bern_pi\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97114e8b-09ad-4151-9dc6-99a33947eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a9ede3-9bf3-417f-9680-8a95b7daa605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/bern_pi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75264aa-e069-4b1e-8a6b-4c93f17d9021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>grp</th>\n",
       "      <th>utype</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rutgers english phd: i write without knowing t...</td>\n",
       "      <td>27</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont bite unless asked</td>\n",
       "      <td>5</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foreign policy</td>\n",
       "      <td>27</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floridian</td>\n",
       "      <td>27</td>\n",
       "      <td>influencer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>live la vida bila loca</td>\n",
       "      <td>27</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 col grp       utype  count\n",
       "0  rutgers english phd: i write without knowing t...  27    ordinary      1\n",
       "1                             dont bite unless asked   5    ordinary      1\n",
       "2                                     foreign policy  27    ordinary     16\n",
       "3                                          floridian  27  influencer      1\n",
       "4                             live la vida bila loca  27    ordinary      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49cb070-65bf-4c2c-87a8-715d56597e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"Fx to get weighted log odds\"\"\"\n",
    "def get_weighted_log_odds(dataFrame, groupSet, featureName, nCount):\n",
    "    \"\"\"\n",
    "    Fx to get weighted log odds ratio of features depending on their grouping.\n",
    "    Adapted from https://github.com/juliasilge/tidylo/blob/main/R/bind_log_odds.R\n",
    "    Input is a dataframe that has columns of your set (groups you are comparing to one another),\n",
    "    feature (the thing you want to see the weighted log odds of) and the count (n) of\n",
    "    features per set. This is flexible enough to get weighted log odds of any set, feature\n",
    "    and count combination.\n",
    "    \"\"\"\n",
    "    alphas = dataFrame.groupby(featureName).sum(nCount).reset_index()[[featureName, nCount]].rename(columns={nCount:'alpha'})  # Get total # of features across whole dataset\n",
    "    dataFrame_II = dataFrame.merge(alphas, on= featureName, how = 'left')\n",
    "    dataFrame_II['y_wi'] = dataFrame_II[nCount] + dataFrame_II['alpha']  # \"y_wi is the pseudo count of word w in group i\"\n",
    "    y_ws = dataFrame_II.groupby(featureName).sum('y_wi').reset_index()[[featureName, 'y_wi']].rename(columns={'y_wi': 'y_w'})  # \"y_w is the total count of word w\"\n",
    "    # Actually is sort of an exaggerated count ¯\\_(ツ)_/¯\n",
    "    dataFrame_III = dataFrame_II.merge(y_ws, on=featureName, how='left')\n",
    "    # Do exaggerated count per set:\n",
    "    n_is = dataFrame_II.groupby(groupSet).sum('y_wi').reset_index()[[groupSet, 'y_wi']].rename(columns={'y_wi': 'n_i'})\n",
    "    pseudo_counts = dataFrame_III.merge(n_is, on= groupSet, how = 'left')  # Combine everything together! Now ready to do weighted log odds calc\n",
    "    pseudo_counts['omega_wi'] = pseudo_counts['y_wi'] / (pseudo_counts['n_i'] - pseudo_counts['y_wi'])  # # odds in group i\n",
    "    pseudo_counts['omega_w'] = pseudo_counts['y_w'] / (sum(pseudo_counts['y_wi']) - pseudo_counts['y_w'])  # overall odds\n",
    "    pseudo_counts['delta_wi'] = (np.log(pseudo_counts['omega_wi'])) - (np.log(pseudo_counts['omega_w']))   # eqn 15 << not sure what this means, it's in OG R code\n",
    "    pseudo_counts['sigma2_wi'] = 1 / pseudo_counts['y_wi'] + 1 / pseudo_counts['y_w']           # eqn 18\n",
    "    pseudo_counts['zeta_wi'] = pseudo_counts['delta_wi'] / (np.sqrt(pseudo_counts['sigma2_wi']))       # eqn 21\n",
    "    return pseudo_counts.rename(columns={'zeta_wi': 'log_odds_weighted', 'delta_wi': 'log_odds'}).sort_values('log_odds_weighted', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d1f88b-8dfa-4911-928e-73b42bdde4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['col','grp','utype','n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c127a163-9ca4-44df-a721-b61b5606c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = get_weighted_log_odds(df[df.utype == \"influencer\"], \"grp\",\"col\",\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058f038f-0322-4d3c-8bc1-ddd33dc5a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '5', '11', '19', '27'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res.grp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4640f43-996e-4528-b84b-b0878a7c0b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \t bernie2020, he, him, notmeus, she, medicareforall, her, progressive, berniesanders, blacklivesmatter, writer, blm, greennewdeal, gnd, activist, neverbiden, they, host, socialist, organizer, democratic socialist, author, alum, founder, generalstrike\n",
      "5 \t he, she, him, bernie2020, her, medicareforall, m4a, notmeus, blm, they, blacklivesmatter, writer, medicare4all, 18, fan account, berniesanders, politics, votegreen, 21, artist, acab, demexit, them, neverbidennevertrump, 22\n",
      "11 \t outline, staff writer, deadspin, curaffairs, newrepublic, writer, bylines, gmail, nytimes, vice, horror, gqmagazine, tv writer, tim, trashfuturepod, paste, eattherichpod, any, rip, labor, thebafflermag, listen to, podcasts, jewishcurrents, researcher\n",
      "19 \t nomiddleground, bernie, green, peoplesparty, freecollege, freeassange, independent voter, bernieontheballot, ventura2020, tenforjustice, ibelievetarareade, votegreen, m4all, gogreen, nevertrumpneverbiden, end the wars, software engineer, bernietogreen, solidarity, 4apeoplesparty, nocomradesunder1k, living wage, bernienina2020, anti-establishment, greenparty2020\n",
      "27 \t dad, workingfamilies, join us, nycdsa, cpdaction, covering 2020, popdemoc, politico, nytimes, bernie, ufcw400, pplsaction, political reporter, political strategist, steering committee, wbng32035, national surrogate, israel, 2020 campaign reporter, organizing, bylines, homesguarantee, labor, field director, amarch4ourlives\n"
     ]
    }
   ],
   "source": [
    "for g in df_res.grp.unique():\n",
    "    print(g + \" \\t \" + \", \".join(df_res[(df_res.grp == g)  ].sort_values(\n",
    "        \"log_odds_weighted\",ascending=False).iloc[:25].col) + \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
